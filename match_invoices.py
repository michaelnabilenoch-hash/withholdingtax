import io
import re
from itertools import combinations
import numpy as np
import pandas as pd
import streamlit as st
from difflib import SequenceMatcher

# ============================================================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
# ============================================================
COL_INV = "ÙÙˆØ§ØªÙŠØ±"
COL_DATE = "Ø§Ù„ØªØ§Ø±ÙŠØ®"
COL_NAME = "Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©"
COL_AMOUNT = "ØµØ§ÙÙ‰ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª"

COL_TAX_NAME = "Ø§Ø³Ù… Ø§Ù„Ø¬Ù‡Ø©"
COL_TAX_AMOUNT = "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØµØ§ÙÙŠØ© Ù„Ù„ØªØ¹Ø§Ù…Ù„"
COL_TAX_TAXED = "Ù…Ø­ØµÙ„ Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¶Ø±ÙŠØ¨Ù‡"
COL_TAX_RATE = "Ù†Ø³Ø¨Ø© Ø§Ù„Ø®ØµÙ…"
COL_TAX_DATE = "ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ø§Ù…Ù„"

NEW_COLS = [
    "Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø±Ù‚Ù… Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
    "Ø³Ù†Ø© Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
    "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
    "Ù…Ø¨Ù„Øº Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„Ù„ØªØ­Ù‚Ù‚",
    "Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¹Ù† Ø§Ù„Ù…Ø±ØªØ¬Ø¹",
]

# ============================================================
# Ø¯ÙˆØ§Ù„ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡
# ============================================================
STOPWORDS = {
    "Ø´Ø±ÙƒØ©", "Ø§Ù„Ø´Ø±ÙƒØ©", "Ø´Ø±ÙƒÙ‡", "Ø§Ù„Ø´Ø±ÙƒÙ‡", "ÙˆØ§Ù„", "Ù„Ù„", "Ù„", "Ù…ØµØ±", "Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©",
    "Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©", "Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©", "Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©", "Ù…ØµÙ†Ø¹", "Ø§Ù„ØµÙ†Ø§Ø¹Ø§Øª", "Ù„Ù„ØªØ¬Ø§Ø±Ø©", "ØªØ¬Ø§Ø±ÙŠØ©",
    "Ø¬Ø±ÙˆØ¨", "Ù„Ù„ØµÙ†Ø§Ø¹Ø§Øª", "Ø§Ù„ØºØ°Ø§Ø¦ÙŠØ©", "Ø§Ø¬Ø±ÙˆØ§Ù†Ø¯Ø³", "ÙˆØ§Ù„ØµÙ†Ø§Ø¹Ø§Øª"
}

WORD_MAP = {
    "Ø§Ù„ØµØ±Ù": "ØµØ±Ù", "ÙˆØ§Ù„ØµØ±Ù": "ØµØ±Ù", "ØµØ±Ù Ø§Ù„ØµØ­ÙŠ": "ØµØ±Ù ØµØ­ÙŠ",
    "Ø§Ù„Ø´Ø±Ø¨": "Ø´Ø±Ø¨", "Ø§Ù„Ù…ÙŠØ§Ù‡": "Ù…ÙŠØ§Ù‡", "Ø§Ù„Ù…ÙŠØ§Ø©": "Ù…ÙŠØ§Ù‡", "Ù…ÙŠØ§Ø©": "Ù…ÙŠØ§Ù‡",
    "Ø¨Ø³ÙˆÙ‡Ø¬": "Ø¨Ø³ÙˆÙ‡Ø§Ø¬", "Ø¨Ø³ÙˆÙ‡Ù€Ø§Ø¬": "Ø¨Ø³ÙˆÙ‡Ø§Ø¬",
    "Ø§Ù„Ø²Ø±Ø§Ø¹Ù‰": "Ø²Ø±Ø§Ø¹ÙŠ", "Ø§Ù„Ø²Ø±Ø§Ø¹ÙŠ": "Ø²Ø±Ø§Ø¹ÙŠ", "Ù„Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±": "Ø§Ø³ØªØ«Ù…Ø§Ø±",
    "ÙƒÙ„ÙŠÙˆØ¨Ø§ØªØ±Ø§": "ÙƒÙ„ÙŠÙˆØ¨Ø§ØªØ±Ø§",  # Ù†Ø«Ø¨Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
}

def normalize_letters(text):
    if pd.isna(text): return ""
    s = str(text)
    s = re.sub(r"[Ø£Ø¥Ø¢Ø§]", "Ø§", s)
    s = re.sub(r"[Ø©]", "Ù‡", s)
    s = re.sub(r"[Ù‰ÙŠØ¦]", "ÙŠ", s)
    s = re.sub(r"[Ø¤]", "Ùˆ", s)
    s = re.sub(r"[Ù‹ÙŒÙÙÙÙÙ‘Ù’Ù€]", "", s)
    return s

def remove_al_prefix(word):
    for pref in ("ÙˆØ§Ù„", "Ø¨Ø§Ù„", "Ù„Ù„", "Ø§Ù„", "Ù„"):
        if word.startswith(pref) and len(word) > len(pref) + 1:
            return word[len(pref):]
    return word

def normalize_name(s):
    if pd.isna(s): return ""
    s = normalize_letters(s).lower()
    s = re.sub(r"[^Ø¡-ÙŠ\s]", " ", s)
    words = [remove_al_prefix(w) for w in s.split() if w.strip()]
    normalized = [WORD_MAP.get(w, w) for w in words]
    final = " ".join(normalized)
    for k, v in WORD_MAP.items():
        final = re.sub(rf"\b{k}\b", v, final)
    return re.sub(r"\s+", " ", final).strip()

def tokenize(s):
    norm = normalize_name(s)
    return set(w for w in norm.split() if w and w not in STOPWORDS)

def fuzzy(a, b):
    return SequenceMatcher(None, a, b).ratio()

def to_num(v):
    try:
        return float(str(v).replace(",", "").strip())
    except:
        return np.nan

def parse_dates(series, dayfirst):
    dt = pd.to_datetime(series, errors="coerce", dayfirst=dayfirst)
    return dt, dt.dt.year.fillna(0).astype(int), dt.dt.month.fillna(0).astype(int)

# ============================================================
# ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ù„ÙØ§Øª
# ============================================================
def prepare_sales(df_raw):
    df = df_raw.copy()
    df["amt"] = df[COL_AMOUNT].apply(to_num)
    
    grouped = df.groupby(COL_INV).agg(
        net_amount=("amt", "sum"),
        pos_date=(COL_DATE, lambda x: x[df.loc[x.index, "amt"] > 0].iloc[0] if any(df.loc[x.index, "amt"] > 0) else np.nan),
        has_return=("amt", lambda s: any(s < 0)),
        name=(COL_NAME, "first"),
    ).reset_index()
    
    grouped = grouped[grouped["net_amount"] > 0]
    grouped["date_parsed"], grouped["year"], grouped["month"] = parse_dates(grouped["pos_date"], dayfirst=True)
    grouped["name_norm"] = grouped["name"].apply(normalize_name)
    grouped["tokens"] = grouped["name"].apply(tokenize)
    return grouped

def prepare_tax(df_raw):
    df = df_raw.copy()
    df["v_file"] = df[COL_TAX_AMOUNT].apply(to_num)
    df["v_tax_paid"] = df[COL_TAX_TAXED].apply(to_num)
    
    def rate_to_float(x):
        try:
            return float(str(x).replace("%", "").strip()) / 100.0
        except:
            return np.nan
    
    df["rate"] = df[COL_TAX_RATE].apply(rate_to_float)
    df["v_tax"] = df.apply(lambda r: r["v_tax_paid"] / r["rate"] if pd.notna(r["v_tax_paid"]) and pd.notna(r["rate"]) and r["rate"] > 0 else np.nan, axis=1)
    df["v_mix"] = df[["v_file", "v_tax"]].mean(axis=1, skipna=True)
    df["date_parsed"], df["year"], df["month"] = parse_dates(df[COL_TAX_DATE], dayfirst=True)
    df["name_norm"] = df[COL_TAX_NAME].apply(normalize_name)
    df["tokens"] = df[COL_TAX_NAME].apply(tokenize)
    return df

# ============================================================
# ÙÙ„Ø§ØªØ± Ø§Ù„Ø¨Ø­Ø« - Ù…Ø­Ø³Ù‘Ù†
# ============================================================
def filter_year_and_date(sales_df, tax_date, tax_year, tax_month):
    """
    ÙÙ„ØªØ± Ù…ÙˆØ³Ù‘Ø¹: ÙŠØ¨Ø­Ø« ÙÙŠ Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© + Ø§Ù„Ø³Ù†ØªÙŠÙ† Ø§Ù„Ù„ÙŠ Ù‚Ø¨Ù„Ù‡Ø§
    Ù„ØªØºØ·ÙŠØ© Ø­Ø§Ù„Ø§Øª Ø§Ù„ØªØ£Ø®ÙŠØ± ÙÙŠ Ø§Ù„Ø¥Ù‚Ø±Ø§Ø±
    """
    if tax_year == 0 or pd.isna(tax_date):
        return sales_df.iloc[0:0]
    
    # Ù†Ø¨Ø­Ø« ÙÙŠ 3 Ø³Ù†ÙˆØ§Øª: Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙˆØ§Ù„Ø³Ù†ØªÙŠÙ† Ø§Ù„Ù„ÙŠ Ù‚Ø¨Ù„Ù‡Ø§
    allowed_years = [tax_year, tax_year - 1, tax_year - 2]
    mask_year = sales_df["year"].isin(allowed_years)
    
    # Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„Ø§Ø²Ù… ÙŠÙƒÙˆÙ† Ù‚Ø¨Ù„ Ø£Ùˆ ÙŠØ³Ø§ÙˆÙŠ ØªØ§Ø±ÙŠØ® ÙƒØ´Ù Ø§Ù„Ø®ØµÙ…
    mask_date = (sales_df["date_parsed"] <= tax_date)
    
    return sales_df[mask_year & mask_date]

def extended_subset_search(cand, targets, max_invoices=50, max_nodes=200000):
    if not targets: return None
    max_t, min_t = max(targets), min(targets)
    
    cand = cand.head(max_invoices).sort_values("net_amount", ascending=False)
    rows = list(cand.itertuples(index=False))
    n = len(rows)
    if n == 0: return None
    
    amounts = [r.net_amount for r in rows]
    suffix = [0.0] * (n + 1)
    for i in range(n - 1, -1, -1):
        suffix[i] = suffix[i + 1] + amounts[i]
    
    best = None
    best_diff = float("inf")
    nodes = 0
    
    def dfs(i, cur_sum, chosen):
        nonlocal best, best_diff, nodes
        nodes += 1
        if nodes > max_nodes or cur_sum > max_t * 1.05: return
        if cur_sum + suffix[i] < min_t * 0.95: return
        if i == n:
            diff = min(abs(cur_sum - t) for t in targets)
            if diff <= 0.05 * max_t and diff < best_diff:
                best_diff = diff
                best = chosen[:]
            return
        chosen.append(i)
        dfs(i + 1, cur_sum + amounts[i], chosen)
        chosen.pop()
        dfs(i + 1, cur_sum, chosen)
    
    dfs(0, 0.0, [])
    return [rows[i] for i in best] if best else None

# ============================================================
# Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© - Ù…Ø­Ø³Ù‘Ù†Ø© Ø¬Ø¯Ø§Ù‹
# ============================================================
def find_best_match(tax_row, sales_df, used_invoices):
    tax_date = tax_row["date_parsed"]
    if pd.isna(tax_date): return None
    
    v_file, v_tax, v_mix = tax_row["v_file"], tax_row["v_tax"], tax_row["v_mix"]
    targets = [t for t in (v_file, v_tax, v_mix) if pd.notna(t) and t > 0]
    if not targets: return None
    
    # ÙÙ„ØªØ± Ù…ÙˆØ³Ù‘Ø¹ Ù„Ù„Ø³Ù†ÙˆØ§Øª
    cand = filter_year_and_date(sales_df, tax_date, tax_row["year"], tax_row["month"])
    if cand.empty: return None
    
    cand = cand[~cand[COL_INV].astype(str).isin(used_invoices)].copy()
    if cand.empty: return None
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    cand["token_score"] = cand["tokens"].apply(lambda t: len(t & tax_row["tokens"]))
    cand["fuzzy"] = cand["name_norm"].apply(lambda s: fuzzy(s, tax_row["name_norm"]))
    
    # ÙÙ„ØªØ± Ù…ØªÙˆØ§Ø²Ù†
    cand = cand[(cand["token_score"] >= 1) | (cand["fuzzy"] >= 0.75)]
    if cand.empty: return None
    
    def within_pct(val, pct=0.05):
        return any(abs(val - t) <= pct * t for t in targets)
    
    def within_absolute(val, max_diff=1.0):
        """Ù„Ù„Ù…Ø¨Ø§Ù„Øº Ø§Ù„Ù…ØªØ·Ø§Ø¨Ù‚Ø© ØªÙ…Ø§Ù…Ø§Ù‹ (ÙØ±Ù‚ â‰¤ 1 Ø¬Ù†ÙŠÙ‡)"""
        return any(abs(val - t) <= max_diff for t in targets)
    
    cand["value_dist"] = cand["net_amount"].apply(lambda x: min(abs(x - t) for t in targets))
    
    # ØªØ±ØªÙŠØ¨ Ø£Ø°ÙƒÙ‰: Ø§Ù„Ø£Ù‚Ø±Ø¨ ÙÙŠ Ø§Ù„Ù…Ø¨Ù„Øº Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø«Ù… Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù„ÙØ¸ÙŠ
    cand = cand.sort_values(
        by=["value_dist", "token_score", "fuzzy"], 
        ascending=[True, False, False]
    )
    
    # ğŸ”¥ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø£ÙˆÙ„Ù‰: ÙØ§ØªÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ù…ØªØ·Ø§Ø¨Ù‚Ø© ØªÙ…Ø§Ù…Ø§Ù‹ (ÙØ±Ù‚ â‰¤ 1 Ø¬Ù†ÙŠÙ‡)
    for _, r in cand.head(100).iterrows():
        if within_absolute(r["net_amount"], max_diff=1.0):
            return [str(r[COL_INV])], [str(r["year"])], [str(r["pos_date"])], float(r["net_amount"]), r["has_return"]
    
    # ğŸ¯ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: ÙØ§ØªÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙŠ Ø­Ø¯ÙˆØ¯ 5%
    for _, r in cand.head(50).iterrows():
        if within_pct(r["net_amount"]):
            return [str(r[COL_INV])], [str(r["year"])], [str(r["pos_date"])], float(r["net_amount"]), r["has_return"]
    
    # âš¡ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø«Ø§Ù„Ø«Ø©: Ù…Ø¬Ù…ÙˆØ¹ 2 ÙÙˆØ§ØªÙŠØ± Ù…ØªØ·Ø§Ø¨Ù‚ ØªÙ…Ø§Ù…Ø§Ù‹
    for combo in combinations(cand.head(80).itertuples(index=False), 2):
        total = sum(r.net_amount for r in combo)
        if not within_absolute(total, max_diff=1.0): continue
        invs = [str(r._asdict()[COL_INV]) for r in combo]
        if len(set(invs)) != len(invs): continue
        years = [str(r.year) for r in combo]
        dates = [str(r.pos_date) for r in combo]
        ret = any(r.has_return for r in combo)
        return invs, years, dates, float(total), ret
    
    # ğŸ“Š Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø±Ø§Ø¨Ø¹Ø©: Ù…Ø¬Ù…ÙˆØ¹ 2-3 ÙÙˆØ§ØªÙŠØ± ÙÙŠ Ø­Ø¯ÙˆØ¯ 5%
    for n in [2, 3]:
        for combo in combinations(cand.head(80).itertuples(index=False), n):
            total = sum(r.net_amount for r in combo)
            if not within_pct(total): continue
            invs = [str(r._asdict()[COL_INV]) for r in combo]
            if len(set(invs)) != len(invs): continue
            years = [str(r.year) for r in combo]
            dates = [str(r.pos_date) for r in combo]
            ret = any(r.has_return for r in combo)
            return invs, years, dates, float(total), ret
    
    # ğŸš€ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ø®Ø§Ù…Ø³Ø©: Ø¨Ø­Ø« Ù…ÙˆØ³Ø¹ Ù„Ù„Ù…Ø¨Ø§Ù„Øº Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
    if max(targets) >= 100000:
        ext = extended_subset_search(cand, targets)
        if ext:
            total = sum(r.net_amount for r in ext)
            if within_pct(total):
                invs = [str(r._asdict()[COL_INV]) for r in ext]
                years = [str(r.year) for r in ext]
                dates = [str(r.pos_date) for r in ext]
                ret = any(r.has_return for r in ext)
                return invs, years, dates, float(total), ret
    
    return None

def match_all(sales_df, tax_df):
    used = set()
    result = tax_df.copy()
    for col in NEW_COLS:
        result[col] = ""
    
    matched = 0
    for idx, row in result.iterrows():
        res = find_best_match(row, sales_df, used)
        if res:
            invs, years, dates, amt, has_ret = res
            result.at[idx, NEW_COLS[0]] = " + ".join(invs)
            result.at[idx, NEW_COLS[1]] = " + ".join(years)
            result.at[idx, NEW_COLS[2]] = " + ".join(dates)
            result.at[idx, NEW_COLS[3]] = amt
            result.at[idx, NEW_COLS[4]] = "Ù„Ù‡ Ù…Ø±ØªØ¬Ø¹" if has_ret else ""
            used.update(invs)
            matched += 1
    
    return result, matched, len(result) - matched

# ============================================================
# ÙˆØ§Ø¬Ù‡Ø© Streamlit
# ============================================================
st.set_page_config(page_title="Ù…Ø·Ø§Ø¨Ù‚Ø© Ø®ØµÙ… Ø§Ù„Ù…Ù†Ø¨Ø¹ 2025", layout="wide")
st.title("ğŸ¯ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø®ØµÙ… Ø§Ù„Ù…Ù†Ø¨Ø¹ - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©")
st.markdown("""
**âœ¨ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:**
- ğŸ” Ø¨Ø­Ø« ÙÙŠ 3 Ø³Ù†ÙˆØ§Øª (Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø³Ù†Ø© ÙˆØ§Ø­Ø¯Ø©)
- ğŸ¯ Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…ØªØ·Ø§Ø¨Ù‚Ø© ØªÙ…Ø§Ù…Ø§Ù‹ (ÙØ±Ù‚ â‰¤ 1 Ø¬Ù†ÙŠÙ‡)
- âš¡ ØªØ±ØªÙŠØ¨ Ø£Ø°ÙƒÙ‰ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¨Ù„Øº Ø£ÙˆÙ„Ø§Ù‹
- ğŸ“Š Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©
""")

c1, c2 = st.columns(2)
with c1:
    sales_file = st.file_uploader("ğŸ“Š Ù…Ù„Ù Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª (CSV)", type="csv")
with c2:
    tax_file = st.file_uploader("ğŸ“‘ ÙƒØ´Ù Ø®ØµÙ… Ø§Ù„Ù…Ù†Ø¨Ø¹ (CSV)", type="csv")

if st.button("ğŸš€ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¢Ù†", type="primary"):
    if not sales_file or not tax_file:
        st.error("âš ï¸ Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ø£ÙˆÙ„Ø§Ù‹!")
    else:
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©..."):
            sales_raw = pd.read_csv(sales_file, encoding="utf-8-sig", dtype=str)
            tax_raw = pd.read_csv(tax_file, encoding="utf-8-sig", dtype=str)
            
            sales_prepared = prepare_sales(sales_raw)
            tax_prepared = prepare_tax(tax_raw)
            
            final_df, ok, bad = match_all(sales_prepared, tax_prepared)
            
            success_rate = (ok/(ok+bad)*100) if (ok+bad) > 0 else 0
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø¬Ø°Ø§Ø¨Ø©
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("âœ… Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚", f"{ok:,}", delta="Ù†Ø¬Ø­")
            with col2:
                st.metric("âŒ ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚", f"{bad:,}", delta="Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©")
            with col3:
                st.metric("ğŸ“ˆ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­", f"{success_rate:.2f}%")
            
            st.divider()
            
            output = io.BytesIO()
            final_df.to_csv(output, index=False, encoding="utf-8-sig")
            st.download_button(
                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØ´Ù Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©",
                data=output.getvalue(),
                file_name="ÙƒØ´Ù_Ù…Ø·Ø§Ø¨Ù‚_Ø°Ù‡Ø¨ÙŠ.csv",
                mime="text/csv",
                use_container_width=True
            )
            
            unmatched = final_df[final_df[NEW_COLS[0]] == ""]
            if not unmatched.empty:
                out2 = io.BytesIO()
                unmatched.to_csv(out2, index=False, encoding="utf-8-sig")
                st.download_button(
                    label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ ÙÙ‚Ø· (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ©)",
                    data=out2.getvalue(),
                    file_name="ØºÙŠØ±_Ù…Ø·Ø§Ø¨Ù‚_Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©.csv",
                    mime="text/csv",
                    use_container_width=True
                )

st.markdown("---")
st.caption("ğŸ’¼ ØªØ·ÙˆÙŠØ±: Ù…Ø­Ø§Ø³Ø¨ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…Ø§ÙŠÙƒÙ„ Ù†Ø¨ÙŠÙ„ | ğŸš€ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ© 2025")
