import io
import re
from itertools import combinations
from math import isfinite

import numpy as np
import pandas as pd
import streamlit as st
from difflib import SequenceMatcher

# ============================================================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (ØºÙŠÙ‘Ø±Ù‡Ø§ Ù„Ùˆ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¹Ù†Ø¯Ùƒ Ù…Ø®ØªÙ„ÙØ©)
# ============================================================
COL_INV = "ÙÙˆØ§ØªÙŠØ±"              # Ø±Ù‚Ù… Ø§Ù„ÙØ§ØªÙˆØ±Ø© ÙÙŠ Ù…Ù„Ù Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª
COL_DATE = "Ø§Ù„ØªØ§Ø±ÙŠØ®"             # ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ§ØªÙˆØ±Ø©
COL_NAME = "Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒØ©"          # Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙÙŠ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª
COL_AMOUNT = "ØµØ§ÙÙ‰ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª"     # ØµØ§ÙÙŠ Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª

COL_TAX_NAME = "Ø§Ø³Ù… Ø§Ù„Ø¬Ù‡Ø©"         # Ø§Ø³Ù… Ø§Ù„Ø¬Ù‡Ø© ÙÙŠ ÙƒØ´Ù Ø§Ù„Ø®ØµÙ…
COL_TAX_AMOUNT = "Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØµØ§ÙÙŠØ© Ù„Ù„ØªØ¹Ø§Ù…Ù„"
COL_TAX_TAXED = "Ù…Ø­ØµÙ„ Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¶Ø±ÙŠØ¨Ù‡"   # Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ù…Ø®ØµÙˆÙ… (Ø§Ù„Ø¶Ø±ÙŠØ¨Ø©)
COL_TAX_RATE = "Ù†Ø³Ø¨Ø© Ø§Ù„Ø®ØµÙ…"        # 0.5% Ø£Ùˆ 1% Ø£Ùˆ 2%
COL_TAX_DATE = "ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ¹Ø§Ù…Ù„"

# Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„Ù„ÙŠ Ù‡ØªØªØ¶Ø§Ù
NEW_COLS = [
    "Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø±Ù‚Ù… Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
    "Ø³Ù†Ø© Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
    "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ§ØªÙˆØ±Ø© Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª",
    "Ù…Ø¨Ù„Øº Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„Ù„ØªØ­Ù‚Ù‚",
    "Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¹Ù† Ø§Ù„Ù…Ø±ØªØ¬Ø¹",
]

# ============================================================
# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ (Ù…Ù…ØªØ§Ø²Ø© Ù„Ù„Ø¹Ø±Ø¨ÙŠ)
# ============================================================
STOPWORDS = {
      "Ø´Ø±ÙƒØ©", "Ø§Ù„Ø´Ø±ÙƒØ©", "Ø´Ø±ÙƒÙ‡", "Ø§Ù„Ø´Ø±ÙƒÙ‡", "ÙˆØ§Ù„", "Ù„Ù„", "Ù„", "Ù…ØµØ±", "Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©",
    "Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©", "Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©", "Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©", "Ù…ØµÙ†Ø¹", "Ø§Ù„ØµÙ†Ø§Ø¹Ø§Øª", "Ù„Ù„ØªØ¬Ø§Ø±Ø©", "ØªØ¬Ø§Ø±ÙŠØ©"
}

WORD_MAP = {
      "Ø§Ù„ØµØ±Ù": "ØµØ±Ù", "ÙˆØ§Ù„ØµØ±Ù": "ØµØ±Ù", "ØµØ±Ù Ø§Ù„ØµØ­ÙŠ": "ØµØ±Ù ØµØ­ÙŠ", "Ø§Ù„ØµØ±Ù Ø§Ù„ØµØ­ÙŠ": "ØµØ±Ù ØµØ­ÙŠ",
    "Ø§Ù„Ø´Ø±Ø¨": "Ø´Ø±Ø¨", "Ø§Ù„Ù…ÙŠØ§Ù‡": "Ù…ÙŠØ§Ù‡", "Ø§Ù„Ù…ÙŠØ§Ø©": "Ù…ÙŠØ§Ù‡", "Ù…ÙŠØ§Ø©": "Ù…ÙŠØ§Ù‡",
    "Ø¨Ø³ÙˆÙ‡Ø¬": "Ø¨Ø³ÙˆÙ‡Ø§Ø¬", "Ø¨Ø³ÙˆÙ‡Ù€Ø§Ø¬": "Ø¨Ø³ÙˆÙ‡Ø§Ø¬", "Ø¨Ø³ÙˆÙ‡Ø§Ø¬": "Ø¨Ø³ÙˆÙ‡Ø§Ø¬",
}

def normalize_letters(text):
    if pd.isna(text):
        return ""
    s = str(text)
    s = re.sub(r"[Ø£Ø¥Ø¢Ø§]", "Ø§", s)
    s = re.sub(r"[Ø©]", "Ù‡", s)
    s = re.sub(r"[Ù‰ÙŠØ¦]", "ÙŠ", s)
    s = re.sub(r"[Ø¤]", "Ùˆ", s)
    s = re.sub(r"[Ù‘ÙÙ‹ÙÙŒÙÙÙ’Ù€]", "", s)
    return s

def remove_al_prefix(word):
    return word[2:] if word.startswith("Ø§Ù„") else word

def normalize_name(s):
    if pd.isna(s):
        return ""
    s = normalize_letters(s).lower()
    s = re.sub(r"[^Ø¡-ÙŠ\s]", " ", s)
    words = [w for w in s.split() if w.strip()]
    words = [remove_al_prefix(w) for w in words]
    normalized = []
    for w in words:
        normalized.append(WORD_MAP.get(w, w))
    final = " ".join(normalized)
    for k, v in WORD_MAP.items():
        final = re.sub(rf"\b{k}\b", v, final)
    final = re.sub(r"\s+", " ", final).strip()
    return final

def strip_prefixes(word):
    # Ù†Ø´ÙŠÙ„ Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©: ÙˆØ§Ù„ØŒ Ø¨Ø§Ù„ØŒ Ù„Ù„ØŒ Ø§Ù„ØŒ Ù„
    for pref in ("ÙˆØ§Ù„", "Ø¨Ø§Ù„", "Ù„Ù„", "Ø§Ù„", "Ù„"):
        if word.startswith(pref) and len(word) > len(pref) + 1:
            return word[len(pref):]
    return word

def tokenize(s):
    norm = normalize_name(s)
    words = [strip_prefixes(w) for w in norm.split() if w.strip()]
    return set(w for w in words if w and w not in STOPWORDS)

def fuzzy(a, b):
    return SequenceMatcher(None, a, b).ratio()

def to_num(v):
    try:
        return float(str(v).replace(",", "").strip())
    except:
        return np.nan

def parse_dates(series, dayfirst):
    dt = pd.to_datetime(series, errors="coerce", dayfirst=dayfirst)
    return dt, dt.dt.year.fillna(0).astype(int), dt.dt.month.fillna(0).astype(int)

# ============================================================
# ØªØ¬Ù‡ÙŠØ² Ù…Ù„Ù Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª
# ============================================================
def prepare_sales(df_raw):
    df = df_raw.copy()
    df["amt"] = df[COL_AMOUNT].apply(to_num)

    grouped = df.groupby(COL_INV).agg(
        net_amount=("amt", "sum"),
        pos_date=(COL_DATE, lambda x: x[df.loc[x.index, "amt"] > 0].iloc[0] if any(df.loc[x.index, "amt"] > 0) else np.nan),
        has_return=("amt", lambda s: any(s < 0)),
        name=(COL_NAME, "first"),
    ).reset_index()

    grouped = grouped[grouped["net_amount"] > 0]

    # Ù‚Ø±Ø§Ø¡Ø© ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø¨ØµÙŠØºØ© ÙŠÙˆÙ…/Ø´Ù‡Ø±/Ø³Ù†Ø©
    grouped["date_parsed"], grouped["year"], grouped["month"] = parse_dates(
        grouped["pos_date"],
        dayfirst=True,
    )

    grouped["name_norm"] = grouped["name"].apply(normalize_name)
    grouped["tokens"] = grouped["name"].apply(tokenize)
    return grouped

# ============================================================
# ØªØ¬Ù‡ÙŠØ² ÙƒØ´Ù Ø§Ù„Ø®ØµÙ…
# ============================================================
def prepare_tax(df_raw):
    df = df_raw.copy()
    df["v_file"] = df[COL_TAX_AMOUNT].apply(to_num)
    df["v_tax_paid"] = df[COL_TAX_TAXED].apply(to_num)

    def rate_to_float(x):
        try:
            return float(str(x).replace("%", "").strip()) / 100.0
        except:
            return np.nan

    df["rate"] = df[COL_TAX_RATE].apply(rate_to_float)

    df["v_tax"] = df.apply(
        lambda r: r["v_tax_paid"] / r["rate"]
        if pd.notna(r["v_tax_paid"]) and pd.notna(r["rate"]) and r["rate"] > 0
        else np.nan,
        axis=1,
    )
    df["v_mix"] = df[["v_file", "v_tax"]].mean(axis=1, skipna=True)
    df["date_parsed"], df["year"], df["month"] = parse_dates(df[COL_TAX_DATE], dayfirst=True)
    df["name_norm"] = df[COL_TAX_NAME].apply(normalize_name)
    df["tokens"] = df[COL_TAX_NAME].apply(tokenize)
    return df

# ============================================================
# ÙÙ„ØªØ± Ø§Ù„Ø³Ù†Ø© ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®
# ============================================================
def filter_year_and_date(sales_df, tax_date, tax_year, tax_month):
    if tax_year == 0 or pd.isna(tax_date):
        return sales_df.iloc[0:0]
    if tax_month in [1, 2, 3]:
        mask_year = (sales_df["year"] == tax_year) | (
            (sales_df["year"] == tax_year - 1) & sales_df["month"].isin([10, 11, 12])
        )
    else:
        mask_year = (sales_df["year"] == tax_year)
    mask_date = (sales_df["date_parsed"] <= tax_date)
    return sales_df[mask_year & mask_date]

# ============================================================
# Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ÙˆØ³Ø¹ (Ù…Ø¬Ù…ÙˆØ¹ ÙÙˆØ§ØªÙŠØ±)
# ============================================================
def extended_subset_search(cand, v_file, v_tax, v_mix, max_invoices=50, max_nodes=200000):
    targets = [t for t in (v_file, v_tax, v_mix) if pd.notna(t) and t > 0]
    if not targets:
        return None

    max_t, min_t = max(targets), min(targets)

    cand = cand.head(max_invoices).sort_values("net_amount", ascending=False)
    rows = list(cand.itertuples(index=False))
    n = len(rows)
    if n == 0:
        return None

    amounts = [r.net_amount for r in rows]
    suffix = [0.0] * (n + 1)
    for i in range(n - 1, -1, -1):
        suffix[i] = suffix[i + 1] + amounts[i]

    best = None
    best_diff = float("inf")
    nodes = 0

    def dfs(i, cur_sum, chosen):
        nonlocal best, best_diff, nodes
        nodes += 1
        if nodes > max_nodes:
            return
        if cur_sum > max_t * 1.05:
            return
        if cur_sum + suffix[i] < min_t * 0.95:
            return
        if i == n:
            diff = min(abs(cur_sum - t) for t in targets)
            if diff <= 0.05 * max_t and diff < best_diff:
                best_diff = diff
                best = chosen[:]
            return
        # Ù†Ø£Ø®Ø°
        chosen.append(i)
        dfs(i + 1, cur_sum + amounts[i], chosen)
        chosen.pop()
        # Ù†ØªØ±Ùƒ
        dfs(i + 1, cur_sum, chosen)

    dfs(0, 0.0, [])
    return [rows[i] for i in best] if best else None

# ============================================================
# Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© (Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©)
# ============================================================
def find_best_match(tax_row, sales_df, used_invoices):
    tax_date = tax_row["date_parsed"]
    if pd.isna(tax_date):
        return None

    v_file = tax_row["v_file"]
    v_tax = tax_row["v_tax"]
    v_mix = tax_row["v_mix"]

    # Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ø­Ø³Ø¨ Ø§Ù„Ø³Ù†Ø© ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®
    cand = filter_year_and_date(sales_df, tax_date, tax_row["year"], tax_row["month"])
    if cand.empty:
        return None

    # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù„ÙŠ Ø§ØªØ§Ø³ØªØ®Ø¯Ù…Øª Ù‚Ø¨Ù„ ÙƒØ¯Ù‡
    cand = cand[~cand[COL_INV].astype(str).isin(used_invoices)]
    if cand.empty:
        return None

def find_best_match(tax_row, sales_df, used_invoices):
    tax_date = tax_row["date_parsed"]
    if pd.isna(tax_date):
        return None

    v_file = tax_row["v_file"]
    v_tax = tax_row["v_tax"]
    v_mix = tax_row["v_mix"]

    # Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ø­Ø³Ø¨ Ø§Ù„Ø³Ù†Ø© ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®
    cand = filter_year_and_date(sales_df, tax_date, tax_row["year"], tax_row["month"])
    if cand.empty:
        return None

    # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù„ÙŠ Ø§ØªØ§Ø³ØªØ®Ø¯Ù…Øª Ù‚Ø¨Ù„ ÙƒØ¯Ù‡
    cand = cand[~cand[COL_INV].astype(str).isin(used_invoices)]
    if cand.empty:
        return None

    cand = cand.copy()
    cand["token_score"] = cand["tokens"].apply(lambda t: len(t & tax_row["tokens"]))
    cand["fuzzy"] = cand["name_norm"].apply(lambda s: fuzzy(s, tax_row["name_norm"]))

    # 1) ÙÙ„ØªØ± Ù…Ø´Ø¯Ù‘Ø¯: Ø§Ø³Ù…ÙŠÙ† Ø´Ø¨Ù‡ Ø¨Ø¹Ø¶ Ø¨Ø¬Ø¯
    strict = cand[(cand["token_score"] >= 2) | (cand["fuzzy"] >= 0.9)]

    if not strict.empty:
        cand = strict.copy()
    else:
        # 2) Ù„Ùˆ Ù…ÙÙŠØ´ ÙˆÙ„Ø§ Ø­Ø§Ø¬Ø©ØŒ Ù†Ø¯ÙŠ ÙØ±ØµØ© Ù„Ø£Ø³Ù…Ø§Ø¡ alias Ù…Ø®ØªØµØ±Ø© (ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©)
        alias = cand[
            (cand["token_score"] >= 1) &
            (cand["tokens"].apply(len) == 1)
        ]
        if alias.empty:
            return None
        cand = alias.copy()

    # ğŸ‘ˆ Ù…Ù‡Ù…: Ù…Ù† Ù‡Ù†Ø§ ÙˆØ·Ø§Ù„Ø¹ Ø¨Ø±Ù‘Ù‡ Ø§Ù„Ù€ elseØŒ Ø¹Ù„Ù‰ Ù†ÙØ³ Ù…Ø³ØªÙˆÙ‰ cand = alias.copy()
    targets = [t for t in (v_file, v_tax, v_mix) if pd.notna(t) and t > 0]
    if not targets:
        return None

    def value_dist(val):
        return min(abs(val - t) for t in targets)

    def within_pct(val, pct=0.05):
        for t in targets:
            if abs(val - t) <= pct * t:
                return True
        return False

    # Ù†Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¹Ø´Ø§Ù† Ø§Ù„ØªØ±ØªÙŠØ¨
    cand["value_dist"] = cand["net_amount"].apply(value_dist)
    cand = cand.sort_values(
        by=["value_dist", "fuzzy", "token_score"],
        ascending=[True, False, False],
    )

    # ============================================
    # 1ï¸âƒ£ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø¬Ù…ÙˆØ¹ 2 Ø£Ùˆ 3 ÙÙˆØ§ØªÙŠØ± Ù‚Ø±ÙŠØ¨ Ø¬Ø¯Ù‹Ø§ (ÙØ±Ù‚ â‰¤ 1 Ø¬Ù†ÙŠÙ‡)
    # ============================================
    best_combo = None
    best_diff = float("inf")

    for n in [2, 3]:
        for combo in combinations(cand.head(80).itertuples(index=False), n):
            total = sum(r.net_amount for r in combo)
            diff = value_dist(total)
            if diff <= 1.0 and diff < best_diff:
                invs = [str(r._asdict()[COL_INV]) for r in combo]
                if len(set(invs)) != len(invs):
                    continue
                best_combo = combo
                best_diff = diff

        if best_combo is not None:
            invs = [str(r._asdict()[COL_INV]) for r in best_combo]
            years = [str(r.year) for r in best_combo]
            dates = [str(r.pos_date) for r in best_combo]
            ret = any(r.has_return for r in best_combo)
            total = sum(r.net_amount for r in best_combo)
            return invs, years, dates, float(total), ret

    # ============================================
    # 2ï¸âƒ£ Ø¨Ø¹Ø¯ ÙƒØ¯Ù‡: ÙØ§ØªÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙŠ Ø­Ø¯ÙˆØ¯ 5%
    # ============================================
    for _, r in cand.head(40).iterrows():
        if within_pct(r["net_amount"], pct=0.05):
            return (
                [str(r[COL_INV])],
                [str(r["year"])],
                [str(r["pos_date"])],
                float(r["net_amount"]),
                r["has_return"],
            )

    # ============================================
    # 3ï¸âƒ£ Ù„Ùˆ Ù…Ø§ÙÙŠØ´: Ù…Ø¬Ù…ÙˆØ¹ 2 Ø£Ùˆ 3 ÙÙˆØ§ØªÙŠØ± ÙÙŠ Ø­Ø¯ÙˆØ¯ 5%
    # ============================================
    for n in [2, 3]:
        for combo in combinations(cand.head(80).itertuples(index=False), n):
            total = sum(r.net_amount for r in combo)
            if not within_pct(total, pct=0.05):
                continue
            invs = [str(r._asdict()[COL_INV]) for r in combo]
            if len(set(invs)) != len(invs):
                continue
            years = [str(r.year) for r in combo]
            dates = [str(r.pos_date) for r in combo]
            ret = any(r.has_return for r in combo)
            return invs, years, dates, float(total), ret

    # ============================================
    # 4ï¸âƒ£ Ø¨Ø­Ø« Ù…ÙˆØ³Ù‘Ø¹ Ù„Ø£ÙŠ Ù…Ø¨Ù„Øº Ù„Ùˆ Ø¹Ø¯Ø¯ Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…Ø±Ø´Ø­Ø© Ù‚Ù„ÙŠÙ„
    # ============================================
    if targets and len(cand) <= 25:
        ext = extended_subset_search(
            cand,
            v_file,
            v_tax,
            v_mix,
            max_invoices=min(len(cand), 25),
        )
        if ext:
            total = sum(r.net_amount for r in ext)
            if within_pct(total, pct=0.05):
                invs = [str(r._asdict()[COL_INV]) for r in ext]
                years = [str(r.year) for r in ext]
                dates = [str(r.pos_date) for r in ext]
                ret = any(r.has_return for r in ext)
                return invs, years, dates, float(total), ret

    return None

    def value_dist(val):
        return min(abs(val - t) for t in targets)

    def within_pct(val, pct=0.05):
        for t in targets:
            if abs(val - t) <= pct * t:
                return True
        return False

    # Ù†Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¹Ø´Ø§Ù† Ø§Ù„ØªØ±ØªÙŠØ¨
    cand["value_dist"] = cand["net_amount"].apply(value_dist)
    cand = cand.sort_values(
        by=["value_dist", "fuzzy", "token_score"],
        ascending=[True, False, False],
    )

    # ============================================
    # 1ï¸âƒ£ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø¬Ù…ÙˆØ¹ 2 Ø£Ùˆ 3 ÙÙˆØ§ØªÙŠØ± Ù‚Ø±ÙŠØ¨ Ø¬Ø¯Ù‹Ø§ (ÙØ±Ù‚ â‰¤ 1 Ø¬Ù†ÙŠÙ‡)
    # ============================================
    best_combo = None
    best_diff = float("inf")

    for n in [2, 3]:
        for combo in combinations(cand.head(80).itertuples(index=False), n):
            total = sum(r.net_amount for r in combo)
            diff = value_dist(total)
            if diff <= 1.0 and diff < best_diff:
                invs = [str(r._asdict()[COL_INV]) for r in combo]
                if len(set(invs)) != len(invs):
                    continue
                best_combo = combo
                best_diff = diff

        if best_combo is not None:
            invs = [str(r._asdict()[COL_INV]) for r in best_combo]
            years = [str(r.year) for r in best_combo]
            dates = [str(r.pos_date) for r in best_combo]
            ret = any(r.has_return for r in best_combo)
            total = sum(r.net_amount for r in best_combo)
            return invs, years, dates, float(total), ret

    # ============================================
    # 2ï¸âƒ£ Ø¨Ø¹Ø¯ ÙƒØ¯Ù‡: ÙØ§ØªÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙŠ Ø­Ø¯ÙˆØ¯ 5%
    # ============================================
    for _, r in cand.head(40).iterrows():
        if within_pct(r["net_amount"], pct=0.05):
            return (
                [str(r[COL_INV])],
                [str(r["year"])],
                [str(r["pos_date"])],
                float(r["net_amount"]),
                r["has_return"],
            )

    # ============================================
    # 3ï¸âƒ£ Ù„Ùˆ Ù…Ø§ÙÙŠØ´: Ù…Ø¬Ù…ÙˆØ¹ 2 Ø£Ùˆ 3 ÙÙˆØ§ØªÙŠØ± ÙÙŠ Ø­Ø¯ÙˆØ¯ 5%
    # ============================================
    for n in [2, 3]:
        for combo in combinations(cand.head(80).itertuples(index=False), n):
            total = sum(r.net_amount for r in combo)
            if not within_pct(total, pct=0.05):
                continue
            invs = [str(r._asdict()[COL_INV]) for r in combo]
            if len(set(invs)) != len(invs):
                continue
            years = [str(r.year) for r in combo]
            dates = [str(r.pos_date) for r in combo]
            ret = any(r.has_return for r in combo)
            return invs, years, dates, float(total), ret

    # ============================================
    # 4ï¸âƒ£ Ø¨Ø­Ø« Ù…ÙˆØ³Ù‘Ø¹ Ù„Ø£ÙŠ Ù…Ø¨Ù„Øº Ù„Ùˆ Ø¹Ø¯Ø¯ Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…Ø±Ø´Ø­Ø© Ù‚Ù„ÙŠÙ„
    #    (Ù…ÙÙŠØ¯ Ù„Ø­Ø§Ù„Ø§Øª Ø²ÙŠ ØªÙƒÙ…ÙŠÙ„ ÙÙŠÙ‡Ø§ 5-10 ÙÙˆØ§ØªÙŠØ± Ù„Ù†ÙØ³ Ø§Ù„Ø¬Ù‡Ø©)
    # ============================================
    if targets and len(cand) <= 25:
        ext = extended_subset_search(
            cand,
            v_file,
            v_tax,
            v_mix,
            max_invoices=min(len(cand), 25),
        )
        if ext:
            total = sum(r.net_amount for r in ext)
            if within_pct(total, pct=0.05):
                invs = [str(r._asdict()[COL_INV]) for r in ext]
                years = [str(r.year) for r in ext]
                dates = [str(r.pos_date) for r in ext]
                ret = any(r.has_return for r in ext)
                return invs, years, dates, float(total), ret

    return None

# ============================================================
# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„
# ============================================================
def match_all(sales_df, tax_df):
    used = set()
    result = tax_df.copy()
    for col in NEW_COLS:
        result[col] = ""

    matched = 0
    for idx, row in result.iterrows():
        res = find_best_match(row, sales_df, used)
        if res:
            invs, years, dates, amt, has_ret = res
            result.at[idx, NEW_COLS[0]] = " + ".join(invs)
            result.at[idx, NEW_COLS[1]] = " + ".join(years)
            result.at[idx, NEW_COLS[2]] = " + ".join(dates)
            result.at[idx, NEW_COLS[3]] = amt
            result.at[idx, NEW_COLS[4]] = "Ù„Ù‡ Ù…Ø±ØªØ¬Ø¹" if has_ret else ""
            used.update(invs)
            matched += 1

    return result, matched, len(result) - matched

# ============================================================
# ÙˆØ§Ø¬Ù‡Ø© Streamlit
# ============================================================
st.set_page_config(page_title="Ù…Ø·Ø§Ø¨Ù‚Ø© Ø®ØµÙ… Ø§Ù„Ù…Ù†Ø¨Ø¹ 2025 - Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", layout="wide")
st.title("Ù…Ø·Ø§Ø¨Ù‚Ø© Ø®ØµÙ… Ø§Ù„Ù…Ù†Ø¨Ø¹ - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨ÙŠ 2025")
st.markdown("**ÙŠØ¯Ø¹Ù… ÙƒÙ„ Ø­Ø§Ø¬Ø©: Ù…Ø±ØªØ¬Ø¹Ø§ØªØŒ Ø­Ø³Ø§Ø¨ Ù…Ù† Ø§Ù„Ø¶Ø±ÙŠØ¨Ø©ØŒ Ù…Ø¨Ø§Ù„Øº ÙƒØ¨ÙŠØ±Ø©ØŒ Ø¹Ø±Ø¨ÙŠ 100%**")

c1, c2 = st.columns(2)
with c1:
    sales_file = st.file_uploader("Ù…Ù„Ù Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª (CSV)", type="csv")
with c2:
    tax_file = st.file_uploader("ÙƒØ´Ù Ø®ØµÙ… Ø§Ù„Ù…Ù†Ø¨Ø¹ (CSV)", type="csv")

if st.button("Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¢Ù†", type="primary"):
    if not sales_file or not tax_file:
        st.error("Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ø£ÙˆÙ„Ø§Ù‹!")
    else:
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©... (Ù…Ù…ÙƒÙ† ÙŠØ§Ø®Ø¯ Ø¯Ù‚Ø§ÙŠÙ‚ Ù„Ùˆ Ø§Ù„Ù…Ù„Ù ÙƒØ¨ÙŠØ±)"):
            sales_raw = pd.read_csv(sales_file, encoding="utf-8-sig", dtype=str)
            tax_raw = pd.read_csv(tax_file, encoding="utf-8-sig", dtype=str)

            sales_prepared = prepare_sales(sales_raw)
            tax_prepared = prepare_tax(tax_raw)

            final_df, ok, bad = match_all(sales_prepared, tax_prepared)

            st.success(
                f"ØªÙ…Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©: {ok:,} ØµÙ | ØºÙŠØ± Ù…Ø·Ø§Ø¨Ù‚: {bad:,} ØµÙ | Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {(ok/(ok+bad)*100):.2f}%"
            )

            # Ù…Ù„Ù ÙƒØ§Ù…Ù„
            output = io.BytesIO()
            final_df.to_csv(output, index=False, encoding="utf-8-sig")
            st.download_button(
                label="ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØ´Ù Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©",
                data=output.getvalue(),
                file_name="ÙƒØ´Ù_Ø®ØµÙ…_Ø§Ù„Ù…Ù†Ø¨Ø¹_Ù…Ø·Ø§Ø¨Ù‚_Ù†Ù‡Ø§Ø¦ÙŠ.csv",
                mime="text/csv",
            )

            # ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ ÙÙ‚Ø·
            unmatched = final_df[final_df[NEW_COLS[0]] == ""]
            if not unmatched.empty:
                out2 = io.BytesIO()
                unmatched.to_csv(out2, index=False, encoding="utf-8-sig")
                st.download_button(
                    label="ØªØ­Ù…ÙŠÙ„ ØºÙŠØ± Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ ÙÙ‚Ø· (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)",
                    data=out2.getvalue(),
                    file_name="ØºÙŠØ±_Ù…Ø·Ø§Ø¨Ù‚_Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©.csv",
                    mime="text/csv",
                )

st.markdown("---")
st.caption("ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© Ù…Ø­Ø§Ø³Ø¨ Ù‚Ø§Ù†ÙˆÙ†Ù‰ : Ù…Ø§ÙŠÙƒÙ„ Ù†Ø¨ÙŠÙ„")
